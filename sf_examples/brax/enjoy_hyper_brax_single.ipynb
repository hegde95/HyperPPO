{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "project_root = os.path.join('/home/shashank/research/hyper/HyperPPO')\n",
    "os.chdir(project_root)\n",
    "%pwd # should be PPGA root dir\n",
    "\n",
    "from IPython.display import HTML, Image\n",
    "from IPython.display import display\n",
    "from brax.io import html, image\n",
    "\n",
    "\n",
    "from sample_factory.enjoy import *\n",
    "from sf_examples.brax.train_brax import register_brax_custom_components, parse_sf_args, add_extra_params_func, override_default_params_func, parse_full_cfg\n",
    "from sample_factory.utils.wandb_utils import init_wandb\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = \"humanoid\"\n",
    "hyper = \"True\"\n",
    "train_dir = \"train_dir/hyper/hyper_\"\n",
    "experiment = \"08_hyper_see_8561347_env_humanoid_d.cri_False_m.std_True_a.s.mod_biased\"\n",
    "# milestone_name = \"checkpoint_000198558_152616960.pth\"\n",
    "milestone_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_brax_cfg(eval_str, evaluation=False):\n",
    "    parser, partial_cfg = parse_sf_args(evaluation=evaluation, argv=eval_str)\n",
    "    add_extra_params_func(parser)\n",
    "    override_default_params_func(partial_cfg.env, parser)\n",
    "    final_cfg = parse_full_cfg(parser,eval_str)\n",
    "    return final_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2023-08-23 18:07:49,948][17523] Environment ant already registered, overwriting...\u001b[0m\n",
      "\u001b[33m[2023-08-23 18:07:49,949][17523] Environment humanoid already registered, overwriting...\u001b[0m\n",
      "\u001b[33m[2023-08-23 18:07:49,950][17523] Environment halfcheetah already registered, overwriting...\u001b[0m\n",
      "\u001b[33m[2023-08-23 18:07:49,951][17523] Environment walker2d already registered, overwriting...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "eval_str = \"python -m sf_examples.brax.enjoy_hyper_brax\"\n",
    "eval_str += f\" --env {env}\"\n",
    "eval_str += f\" --train_dir {train_dir}\"\n",
    "eval_str += f\" --experiment {experiment}\"\n",
    "\n",
    "argv = eval_str.split()[3:]\n",
    "\n",
    "register_brax_custom_components(evaluation=False)\n",
    "cfg = parse_brax_cfg(evaluation=True, eval_str=argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2023-08-23 18:08:03,028][17523] Loading existing experiment configuration from train_dir/hyper/hyper_/08_hyper_see_8561347_env_humanoid_d.cri_False_m.std_True_a.s.mod_biased/config.json\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,029][17523] Overriding arg 'train_dir' with value 'train_dir/hyper/hyper_' passed from command line\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,030][17523] Adding new argument 'fps'=0 that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,030][17523] Adding new argument 'eval_env_frameskip'=None that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,031][17523] Adding new argument 'no_render'=False that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,031][17523] Adding new argument 'save_video'=False that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,032][17523] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,032][17523] Adding new argument 'video_name'=None that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,032][17523] Adding new argument 'max_num_frames'=1000000000.0 that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,033][17523] Adding new argument 'max_num_episodes'=1000000000.0 that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,034][17523] Adding new argument 'push_to_hub'=False that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,034][17523] Adding new argument 'hf_repository'=None that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,035][17523] Adding new argument 'policy_index'=0 that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,035][17523] Adding new argument 'eval_deterministic'=False that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,035][17523] Adding new argument 'train_script'=None that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,036][17523] Adding new argument 'enjoy_script'=None that is not in the saved config file!\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:08:03,036][17523] Using frameskip 1 and render_action_repeat=1 for evaluation\u001b[0m\n",
      "/home/shashank/miniconda3/envs/hyper/lib/python3.9/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "\n",
    "cfg = load_from_checkpoint(cfg)\n",
    "\n",
    "eval_env_frameskip: int = cfg.env_frameskip if cfg.eval_env_frameskip is None else cfg.eval_env_frameskip\n",
    "assert (\n",
    "    cfg.env_frameskip % eval_env_frameskip == 0\n",
    "), f\"{cfg.env_frameskip=} mmilestoneust be divisible by {eval_env_frameskip=}\"\n",
    "render_action_repeat: int = cfg.env_frameskip // eval_env_frameskip\n",
    "cfg.env_frameskip = cfg.eval_env_frameskip = eval_env_frameskip\n",
    "log.debug(f\"Using frameskip {cfg.env_frameskip} and {render_action_repeat=} for evaluation\")\n",
    "\n",
    "cfg.num_envs = 1\n",
    "cfg.env_agents = 1\n",
    "cfg.quads_render = True\n",
    "cfg.max_num_episodes = 4\n",
    "cfg.eval_deterministic = True\n",
    "\n",
    "render_mode = \"human\"\n",
    "# render_mode = None\n",
    "if cfg.save_video:\n",
    "    render_mode = \"rgb_array\"\n",
    "elif cfg.no_render:\n",
    "    render_mode = None\n",
    "\n",
    "env = make_env_func_batched(\n",
    "    cfg, env_config=AttrDict(worker_index=0, vector_index=0, env_id=0), render_mode=render_mode\n",
    ")\n",
    "env_info = extract_env_info(env, cfg)\n",
    "\n",
    "if hasattr(env.unwrapped, \"reset_on_init\"):\n",
    "    # reset call ruins the demo recording for VizDoom\n",
    "    env.unwrapped.reset_on_init = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[2023-08-23 18:13:25,266][17523] RunningMeanStd input shape: (240,)\u001b[0m\n",
      "\u001b[36m[2023-08-23 18:13:25,302][17523] RunningMeanStd input shape: (1,)\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AttrDict' object has no attribute 'milestone_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m name_prefix \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(latest\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m, best\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest\u001b[39m\u001b[39m\"\u001b[39m)[cfg\u001b[39m.\u001b[39mload_checkpoint_kind]\n\u001b[1;32m     12\u001b[0m checkpoints \u001b[39m=\u001b[39m Learner\u001b[39m.\u001b[39mget_checkpoints(Learner\u001b[39m.\u001b[39mcheckpoint_dir(cfg, policy_id), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname_prefix\u001b[39m}\u001b[39;00m\u001b[39m_*\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[39mif\u001b[39;00m cfg\u001b[39m.\u001b[39;49mmilestone_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     checkpoint_dict \u001b[39m=\u001b[39m Learner\u001b[39m.\u001b[39mload_checkpoint(checkpoints, device)\n\u001b[1;32m     17\u001b[0m     milestone_to_load \u001b[39m=\u001b[39m checkpoint_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/research/hyper/sample-factory/sample_factory/utils/attr_dict.py:8\u001b[0m, in \u001b[0;36mAttrDict.__getattribute__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[1;32m      7\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(item)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AttrDict' object has no attribute 'milestone_name'"
     ]
    }
   ],
   "source": [
    "list_of_test_archs = [\n",
    "                [4],                                   \n",
    "            ]\n",
    "actor_critic = create_actor_critic(cfg, env.observation_space, env.action_space)\n",
    "actor_critic.eval()\n",
    "\n",
    "device = torch.device(\"cpu\" if cfg.device == \"cpu\" else \"cuda\")\n",
    "actor_critic.model_to_device(device)\n",
    "\n",
    "policy_id = cfg.policy_index\n",
    "name_prefix = dict(latest=\"checkpoint\", best=\"best\")[cfg.load_checkpoint_kind]\n",
    "checkpoints = Learner.get_checkpoints(Learner.checkpoint_dir(cfg, policy_id), f\"{name_prefix}_*\")\n",
    "\n",
    "\n",
    "if milestone_name is None:\n",
    "    checkpoint_dict = Learner.load_checkpoint(checkpoints, device)\n",
    "    milestone_to_load = checkpoint_dict[\"model\"]\n",
    "else:\n",
    "    milestone_dir = os.path.join(cfg.train_dir, cfg.experiment, \"checkpoint_p0\", \"milestones\")\n",
    "    milestones = Learner.get_checkpoints(milestone_dir, \"checkpoint_*\")\n",
    "    milestone_to_load = [milestone for milestone in milestones if milestone_name in milestone][0]\n",
    "    checkpoint_dict = Learner.load_checkpoint([milestone_to_load], device)\n",
    "\n",
    "actor_critic.load_state_dict(checkpoint_dict[\"model\"])\n",
    "ghn = actor_critic.actor_encoder.ghn\n",
    "ghn.eval()    \n",
    "\n",
    "# test_arch_model = MlpNetwork(fc_layers=arch_to_test, inp_dim = env.observation_space['obs'].shape[0], out_dim = env.action_space.shape[0]).to(device=device)\n",
    "list_of_test_arch_indices = [[i for i,arc in enumerate(actor_critic.actor_encoder.list_of_arcs) if list(arc) == t_arc][0] for t_arc in list_of_test_archs]\n",
    "list_of_test_shape_inds = torch.stack([actor_critic.actor_encoder.list_of_shape_inds[index][0:11] for k,index in enumerate(list_of_test_arch_indices)])\n",
    "\n",
    "# arch_index = [i for i,arc in enumerate(actor_critic.actor_encoder.list_of_arcs) if list(arc) == arch_to_test][0]\n",
    "# shape_ind = actor_critic.actor_encoder.list_of_shape_inds[arch_index]\n",
    "# shape_ind = shape_ind[:torch.where(shape_ind == -1.0)[0][0]]\n",
    "\n",
    "# _ = ghn([test_arch_model], return_embeddings=False, shape_ind = shape_ind.view(-1,1))\n",
    "actor_critic.actor_encoder.set_graph(list_of_test_arch_indices, list_of_test_shape_inds)\n",
    "test_arch_policy = actor_critic.actor_encoder.current_model[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = HTML(html.render(env.unwrapped._env.sys, [s.qp for s in rollout]))\n",
    "display(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
